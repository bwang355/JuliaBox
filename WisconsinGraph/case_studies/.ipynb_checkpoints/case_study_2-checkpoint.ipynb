{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://data.nal.usda.gov/system/files/WI_ACPF_fieldBoundaries_2019.pdf field boundaries from acpf\n",
    "\n",
    "# I believe EPSG 3070 will return meters\n",
    "# WBD came from https://apps.nationalmap.gov/downloader/#/\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import time\n",
    "import os\n",
    "import conda\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from shapely.ops import nearest_points\n",
    "from shapely.geometry import MultiPoint\n",
    "import matplotlib.dates as mdates\n",
    "import math\n",
    "# from shapely.geometry import Polygon as Poly\n",
    "\n",
    "pd.options.display.max_columns = 250\n",
    "pd.options.display.max_rows=150\n",
    "\n",
    "conda_file_dir = conda.__file__\n",
    "conda_dir = conda_file_dir.split('lib')[0]\n",
    "proj_lib = os.path.join(os.path.join(conda_dir, 'share'), 'proj')\n",
    "os.environ[\"PROJ_LIB\"] = proj_lib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm\n",
    "import matplotlib.colors as colors\n",
    "%matplotlib inline\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "import geopandas\n",
    "import geopandas as gpd\n",
    "from geopandas.tools import sjoin\n",
    "import pandas as pd\n",
    "\n",
    "from shapely.geometry import Point\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "import datetime\n",
    "import scipy.stats as st\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "import sys\n",
    "sys.path.insert(1, '../graph_construction/')\n",
    "from WI_graph_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WILakes  = pd.read_pickle(\"../graph_construction/WILakes.df\")\n",
    "WIRivers = pd.read_pickle(\"../graph_construction/WIRivers.df\")\n",
    "agland   = pd.read_pickle(\"../graph_construction/agland.df\")\n",
    "\n",
    "HUC8  = gpd.GeoDataFrame.from_file(\"../graph_construction/WIgeodataframes/HUC8/HUC8.shp\")\n",
    "HUC10 = gpd.GeoDataFrame.from_file(\"../graph_construction/WIgeodataframes/HUC10/HUC10.shp\")\n",
    "HUC12 = gpd.GeoDataFrame.from_file(\"../graph_construction/WIgeodataframes/HUC12/HUC12.shp\")\n",
    "\n",
    "WItofroms       = pd.read_csv(\"../graph_construction/WIgeodataframes/WItofroms.csv\")\n",
    "WItofroms_lakes = pd.read_csv(\"../graph_construction/WIgeodataframes/WItofroms_lakes.csv\")\n",
    "WItofroms_agg   = pd.read_csv(\"../graph_construction/WIgeodataframes/WItofroms_agg.csv\")\n",
    "\n",
    "WI    = gpd.GeoDataFrame.from_file(\"../graph_construction/lakes_rivers/WI/WI.shp\")\n",
    "CAFOS = gpd.GeoDataFrame.from_file(\"../graph_construction/CAFOS_shp/CAFOS_shp.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lake_index = pd.read_csv(\"../DNR_data/lake_index_WBIC_COMID.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 871/871 [00:13<00:00, 64.60it/s]\n"
     ]
    }
   ],
   "source": [
    "WILakes_sub = WILakes.copy(deep=True)\n",
    "WILakes_sub[\"TPavg\"] = 0\n",
    "WILakes_sub[\"chlaavg\"] = 0\n",
    "lakegdf = gpd.GeoDataFrame(columns=WILakes_sub.columns)\n",
    "\n",
    "lake_index[\"TPavg\"]   = 0\n",
    "lake_index[\"chlaavg\"] = 0\n",
    "\n",
    "counter = 0\n",
    "counter5 = 0\n",
    "\n",
    "\n",
    "for i in tqdm(range(len(lake_index))):\n",
    "    lake_num = lake_index.lake_index.iloc[i]\n",
    "    comid = lake_index.COMID.iloc[i]\n",
    "    DNR = pd.read_csv(f\"../DNR_data/Lakes/Lake{lake_num}/DNR_data.csv\")\n",
    "    DNR.date = pd.to_datetime(DNR.date)\n",
    "    \n",
    "    if lake_index.COMID.iloc[i] != 0:\n",
    "        \n",
    "        if len(DNR.TP[DNR.TP.notna()& (DNR.TP != \"ND*\")]) >5 and len(DNR.chla[DNR.chla.notna()& (DNR.chla != \"ND*\")]) > 5:\n",
    "            counter5 += 1\n",
    "\n",
    "        if len(DNR.TP[DNR.TP.notna()& (DNR.TP != \"ND*\")]) >50 and len(DNR.chla[DNR.chla.notna()& (DNR.chla != \"ND*\")]) > 50:\n",
    "            counter += 1\n",
    "            lakegdf = lakegdf.append(WILakes_sub[WILakes_sub.COMID == comid])\n",
    "            lakegdf.TPavg.iloc[-1]     = np.average(DNR.TP.values[DNR.TP.notna() & (DNR.TP != \"ND*\")].astype(float))\n",
    "            lakegdf.chlaavg.iloc[-1]   = np.average(DNR.chla.values[DNR.chla.notna()& (DNR.chla != \"ND*\")].astype(float))\n",
    "            lake_index.TPavg.iloc[i]   = np.average(DNR.TP.values[DNR.TP.notna() & (DNR.TP != \"ND*\")].astype(float))\n",
    "            lake_index.chlaavg.iloc[i] = np.average(DNR.chla.values[DNR.chla.notna()& (DNR.chla != \"ND*\")].astype(float))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#s = tofroms.TOCOMID\n",
    "#r = tofroms.FROMCOMID\n",
    "#Madtofroms = tofroms[s.isin(Madrivers.COMID.values[:]) & r.isin(Madrivers.COMID.values[:])]\n",
    "\n",
    "def plot_with_watersheds(G, G_pos, G_cols, lake_gdf, river_gdf, HUC12, HUC10, WI_too = False,comid_too = False, comid=0, node_size = 20, arrowsize=5):\n",
    "    all_nodes = [i for i in G.nodes]\n",
    "    rivers = river_gdf[river_gdf.COMID.isin(all_nodes)]\n",
    "    lakes  = lake_gdf[lake_gdf.COMID.isin(all_nodes)]\n",
    "    \n",
    "    huc12_rivs  = [i for i in rivers.huc12.values]\n",
    "    \n",
    "    huc12_lakes = [i for i in lakes.huc12.values]\n",
    "    huc12_vals = huc12_lakes + huc12_rivs\n",
    "    huc10_vals = [i for i in lakes.huc10.values]\n",
    "    huc12s     = HUC12[HUC12.huc12.isin(huc12_vals)]\n",
    "    huc10s     = HUC10[HUC10.huc10.isin(huc10_vals)]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(13,13))\n",
    "    nx.draw_networkx(G,pos=G_pos,node_size=node_size,with_labels=False,ax=ax,arrowsize=arrowsize,node_color=G_cols)\n",
    "    huc12s.plot(ax=ax, color=\"none\", edgecolor=\"black\")\n",
    "    lakes.plot(ax=ax, color=\"skyblue\")\n",
    "    if WI_too:\n",
    "        WI.plot(ax=ax, color=\"none\", edgecolor=\"black\")\n",
    "    if comid_too:\n",
    "        WILakes[WILakes.COMID == comid].centroid.plot(ax=ax, markersize=400,marker=\"*\", color=\"gold\",edgecolors=\"black\",linewidth = 1,zorder=151)\n",
    "        #WILakes[WILakes.COMID == comid].plot(ax=ax, color=\"red\")\n",
    "    CAFOS[CAFOS.huc12.isin(huc12_vals)].centroid.plot(ax=ax, markersize=50, color=\"purple\",marker=\"s\", zorder=150)\n",
    "    \n",
    "    legend_elements = [\n",
    "                   Line2D([0],[0], markersize=10, label=\"Waterbody Node\",marker='o', color='blue',linestyle=\"None\"),\n",
    "                   Line2D([0],[0], markersize=10, label=\"River Node\",marker='o',color='red',linestyle=\"None\"),\n",
    "                   Line2D([0],[0], markersize=10, label=\"CAFO\", marker=\"s\", color=\"purple\", linestyle=\"None\"),\n",
    "                   Line2D([0],[0], markersize=18, label=\"Altoona Lake\", marker=\"*\", color=\"gold\", linestyle=\"None\", markeredgecolor=\"black\"),\n",
    "                   Patch(facecolor=\"green\", edgecolor=\"none\", label=\"Agricultural Land\")]\n",
    "\n",
    "    ax.legend(handles=legend_elements, loc = 'upper left',fontsize=22)\n",
    "    #HUC12WI[(HUC12WI.HUC10=='0709000205')|(HUC12WI.HUC10=='0709000206')|(HUC12WI.HUC10=='0709000207')].plot(ax=ax,color=\"none\",edgecolor=\"black\")\n",
    "    #WILakes[(WILakes.HUC10=='0709000205')|(WILakes.HUC10=='0709000206')|(WILakes.HUC10=='0709000207')].plot(ax=ax)\n",
    "    #WIRivers[(WIRivers.HUC10=='0709000205')|(WIRivers.HUC10=='0709000206')|(WIRivers.HUC10=='0709000207')].plot(ax=ax)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def add_CAFOS_to_graph(G_old, lake_gdf, river_gdf, CAFOS):\n",
    "    \n",
    "    G = G_old.copy()\n",
    "    all_nodes = [i for i in G.nodes]\n",
    "    node_df = pd.concat([lake_gdf[[\"COMID\", 'huc12', 'geometry']][lake_gdf.COMID.isin(all_nodes)].copy(), river_gdf[['COMID', 'huc12','geometry']][river_gdf.COMID.isin(all_nodes)].copy()])\n",
    "    \n",
    "    for i in range(len(CAFOS)):\n",
    "        huc = CAFOS.huc12.iloc[i]\n",
    "        point = CAFOS.geometry.iloc[i]\n",
    "        cafo_name = CAFOS.Node.iloc[i]\n",
    "        \n",
    "        df_in_huc = node_df[node_df.huc12 == huc].copy()\n",
    "        df_in_huc = df_in_huc.reset_index(drop=True)\n",
    "        \n",
    "        distances = df_in_huc.distance(point)\n",
    "        \n",
    "        if len(df_in_huc) != 0:\n",
    "            comid_to_connect = df_in_huc.COMID.values[distances == min(distances)][0]\n",
    "        \n",
    "            G.add_edge(cafo_name, comid_to_connect)\n",
    "    return G\n",
    "        \n",
    "def build_graph_with_pollutants(tofroms,lake_gdf, river_gdf, source):\n",
    "    node_df = pd.concat([lake_gdf[[\"COMID\", 'huc12']], river_gdf[['COMID', 'huc12']]])\n",
    "    \n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    for j in range(len(tofroms)):\n",
    "        from_node = tofroms.FROMCOMID.iloc[j]\n",
    "        to_node   = tofroms.TOCOMID.iloc[j]\n",
    "        \n",
    "        if from_node != to_node:\n",
    "            G.add_edge(from_node, to_node)\n",
    "    \n",
    "    all_nodes = [i for i in G.nodes]\n",
    "    \n",
    "    for i in range(len(source)):\n",
    "        huc = source.huc12.iloc[i]\n",
    "        new_df = node_df[(node_df.huc12 == huc) & (node_df.COMID.isin(all_nodes))]\n",
    "        \n",
    "        for j in range(len(new_df)):\n",
    "            from_node = source.Node.iloc[i]\n",
    "            to_node = new_df.COMID.iloc[j]\n",
    "            G.add_edge(from_node, to_node)\n",
    "    return G\n",
    "\n",
    "def get_pos_dict_with_pollutant(G, lake_gdf, riv_gdf, source):\n",
    "    \n",
    "    G_pos = dict()\n",
    "    \n",
    "    node_colors= []\n",
    "    node_size = []\n",
    "    \n",
    "    \n",
    "    for j in tqdm((G.nodes)):\n",
    "        \n",
    "        if np.isin(j, riv_gdf.COMID.values):\n",
    "            poly_val = riv_gdf.geometry[riv_gdf.COMID == j]\n",
    "            cent_val = poly_val.centroid\n",
    "            node_colors.append(\"red\")\n",
    "            node_size.append(10)\n",
    "        elif np.isin(j, source.Node.values):\n",
    "            cent_val = source.geometry[source.Node == j]\n",
    "            node_colors.append(\"orange\")\n",
    "            node_size.append(30)\n",
    "        else:\n",
    "            poly_val = lake_gdf.geometry[lake_gdf.COMID == j]\n",
    "            cent_val = poly_val.centroid\n",
    "            node_colors.append(\"blue\")\n",
    "            node_size.append(10)\n",
    "            \n",
    "        G_pos[j] = (np.array([cent_val.x.values[0], cent_val.y.values[0]]))\n",
    "\n",
    "    return G_pos, node_colors, node_size\n",
    "\n",
    "\n",
    "def add_source_to_graph(G, lake_gdf, river_gdf, source):\n",
    "    all_nodes = [i for i in G.nodes]\n",
    "    node_df = pd.concat([lake_gdf[[\"COMID\", 'huc12', 'geometry']][lake_gdf.COMID.isin(all_nodes)].copy(), river_gdf[['COMID', 'huc12','geometry']][river_gdf.COMID.isin(all_nodes)].copy()])\n",
    "    \n",
    "    for i in range(len(source)):\n",
    "        huc = source.huc12.iloc[i]\n",
    "        point = source.geometry.iloc[i]\n",
    "        cafo_name = source.Node.iloc[i]\n",
    "        \n",
    "        df_in_huc = node_df[node_df.huc12 == huc].copy()\n",
    "        df_in_huc = df_in_huc.reset_index(drop=True)\n",
    "        \n",
    "        distances = df_in_huc.distance(point)\n",
    "        \n",
    "        if len(df_in_huc) != 0:\n",
    "            comid_to_connect = df_in_huc.COMID.values[distances == min(distances)][0]\n",
    "        \n",
    "            G.add_edge(cafo_name, comid_to_connect)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_lakes = build_graph(WItofroms_lakes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 46242/46242 [08:58<00:00, 85.94it/s]\n"
     ]
    }
   ],
   "source": [
    "G_CAFOS = add_CAFOS_to_graph(G_lakes, WILakes, WIRivers, CAFOS)\n",
    "\n",
    "G_CAFOS_pos, node_colors_CAFOS, node_size_CAFOS = get_pos_dict_with_pollutant(G_CAFOS, WILakes, WIRivers, CAFOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_agg = build_graph(WItofroms_agg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 8770/8770 [01:44<00:00, 84.08it/s]\n"
     ]
    }
   ],
   "source": [
    "G_CAFOS2 = add_CAFOS_to_graph(G_agg, WILakes, WIRivers, CAFOS)\n",
    "\n",
    "G_CAFOS_pos2, node_colors_CAFOS2, node_size_CAFOS2 = get_pos_dict_with_pollutant(G_CAFOS2, WILakes, WIRivers, CAFOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#eut_COMIDs = np.unique(lake_index.COMID.values[(lake_index.TPavg>60) & (lake_index.chlaavg>15)]).astype(int)\n",
    "#cln_COMIDs = np.unique(lake_index.COMID.values[(lake_index.TPavg<15) & (lake_index.chlaavg<5) & (lake_index.TPavg != 0) & (lake_index.chlaavg != 0)]).astype(int)\n",
    "\n",
    "eut_lake_index = lake_index[(lake_index.TPavg>110) & (lake_index.chlaavg>30)]\n",
    "cln_lake_index = lake_index[(lake_index.TPavg<10.8) & (lake_index.chlaavg<5) & (lake_index.TPavg != 0) & (lake_index.chlaavg != 0)]\n",
    "\n",
    "eut_COMIDs = np.unique(lake_index.COMID.values[(lake_index.TPavg>110) & (lake_index.chlaavg>30)]).astype(int)\n",
    "cln_COMIDs = np.unique(lake_index.COMID.values[(lake_index.TPavg<10.8) & (lake_index.chlaavg<5) & (lake_index.TPavg != 0) & (lake_index.chlaavg != 0)]).astype(int)\n",
    "\n",
    "G_CAFOS_nodes = [i for i in G_CAFOS.nodes]\n",
    "\n",
    "eut_node_index = eut_lake_index[eut_lake_index.COMID.isin(G_CAFOS_nodes)]\n",
    "cln_node_index = cln_lake_index[cln_lake_index.COMID.isin(G_CAFOS_nodes)]\n",
    "\n",
    "eut_nodes = np.intersect1d(eut_COMIDs, G_CAFOS_nodes).astype(int)\n",
    "cln_nodes = np.intersect1d(cln_COMIDs, G_CAFOS_nodes).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cs2_fig(ax, node, G, G_pos, lake_name, lake_tp, lake_chla, lake_gdf=WILakes, river_gdf=WIRivers, node_size = 4, arrowsize=5, CAFOS=CAFOS):\n",
    "    def get_gdfs(G, comid, lake_gdf=lake_gdf, river_gdf=river_gdf, HUC12 = HUC12, HUC10=HUC10, agland=agland):\n",
    "        all_nodes = [i for i in G.nodes]\n",
    "        all_nodes = all_nodes + [comid]\n",
    "        rivers = river_gdf[river_gdf.COMID.isin(all_nodes)]\n",
    "        lakes  = lake_gdf[lake_gdf.COMID.isin(all_nodes)]\n",
    "        \n",
    "        huc12_rivs  = [i for i in rivers.huc12.values]\n",
    "        \n",
    "        huc12_lakes = [i for i in lakes.huc12.values]\n",
    "        huc12_vals = huc12_lakes + huc12_rivs\n",
    "        huc2       = lake_gdf.huc2[lake_gdf.COMID == comid].iloc[0]\n",
    "        \n",
    "        \n",
    "        huc12_vals = [i for i in huc12_vals if i > huc2*1e10 and i < (huc2*1e10 + 1e10 - 1)]\n",
    "        huc10_vals = [i for i in lakes.huc10.values]\n",
    "        aglands    = agland[agland.huc12.isin(huc12_vals)]\n",
    "        huc12s     = HUC12[HUC12.huc12.isin(huc12_vals)]\n",
    "        huc10s     = HUC10[HUC10.huc10.isin(huc10_vals)]\n",
    "        \n",
    "        aglands    = agland[agland.huc12.isin(huc12_vals)].copy(deep=True)\n",
    "\n",
    "        \n",
    "        huc12s     = HUC12[HUC12.huc12.isin(huc12_vals)]\n",
    "        huc10s     = HUC10[HUC10.huc10.isin(huc10_vals)]\n",
    "        #print(\"starting overlay\")\n",
    "        aglands    = gpd.overlay(aglands, huc12s,how=\"intersection\")\n",
    "        #print(\"done with overlay\")\n",
    "        \n",
    "        return lakes, rivers, huc12s, aglands\n",
    "    \n",
    "    \n",
    "        \n",
    "    g, cols = get_upstream_graph(G, node, lake_gdf, river_gdf)\n",
    "    \n",
    "    lakes, rivers, huc12s, aglands = get_gdfs(g, node)\n",
    "\n",
    "                               \n",
    "    huc12_vals = huc12s.huc12.values\n",
    "    land_frac = sum(aglands.area)/sum(huc12s.area)\n",
    "    \n",
    "    aglands.plot(ax=ax, color=\"forestgreen\")\n",
    "    huc12s.plot(ax=ax, color=\"none\", edgecolor=\"black\")\n",
    "    lakes.plot(ax=ax, color=\"skyblue\")\n",
    "    nx.draw_networkx(g,pos=G_pos,node_size=node_size,with_labels=False,ax=ax,arrowsize=arrowsize,node_color=cols)\n",
    "    \n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_xticks([])\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    #if False:\n",
    "    #    WI.plot(ax=ax, color=\"none\", edgecolor=\"black\")\n",
    "    if True:\n",
    "        WILakes[WILakes.COMID == node].centroid.plot(ax=ax, markersize=350,marker=\"*\", color=\"gold\",edgecolors=\"black\",linewidth = 1,zorder=151)\n",
    "    if len(CAFOS[CAFOS.huc12.isin(huc12_vals)]) > 0:\n",
    "        CAFOS[CAFOS.huc12.isin(huc12_vals)].centroid.plot(ax=ax, markersize=10, color=\"orange\",marker=\"s\", zorder=150)\n",
    "        #WILakes[WILakes.COMID == comid].plot(ax=ax, color=\"red\")\n",
    "\n",
    "    return land_frac\n",
    "        \n",
    "    #ax.set_title(f\"{lake_name} \\nTP avg = {np.round(lake_tp,1)} \"+ r\"$mg/m^3$\" +f\"\\nchla avg = {np.round(lake_chla,1)} \" +r\"$mg/m^3$\"+f\"\\nAg Land = {np.round(land_frac*100,1)} %\",fontsize= 12,loc='left')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(6,5,figsize=(20,16), gridspec_kw={\"height_ratios\":[4,.1, .1, 4, .3, .1]})#[.001,4,.0001,.001,4]})\n",
    "\n",
    "for i in range(5):\n",
    "    lake_vals = eut_node_index[eut_node_index.COMID == eut_nodes[i]]\n",
    "    \n",
    "    lake_name = lake_vals.lakename.iloc[0]\n",
    "    lake_TP   = lake_vals.TPavg.iloc[0]\n",
    "    lake_chla = lake_vals.chlaavg.iloc[0]\n",
    "    \n",
    "    land_frac = make_cs2_fig(ax[0,i], eut_nodes[i], G_CAFOS, G_CAFOS_pos,lake_name, lake_TP, lake_chla)\n",
    "    ax[2,i].set_title(f\"{lake_name} \\nTP avg = {np.round(lake_TP,1)} \"+ r\"$mg/m^3$\" +f\"\\nchla avg = {np.round(lake_chla,1)} \" +r\"$mg/m^3$\"+f\"\\nAg Land = {np.round(land_frac*100,1)} %\",fontsize= 12,loc='left')\n",
    "    ax[2,i].set_axis_off()\n",
    "    ax[1,i].set_axis_off()\n",
    "    \n",
    "for j in range(5):\n",
    "    \n",
    "    lake_vals = cln_node_index[cln_node_index.COMID == cln_nodes[j]]\n",
    "    \n",
    "    \n",
    "    lake_name = lake_vals.lakename.iloc[0]\n",
    "    lake_TP   = lake_vals.TPavg.iloc[0]\n",
    "    lake_chla = lake_vals.chlaavg.iloc[0]\n",
    "    \n",
    "    land_frac = make_cs2_fig(ax[3,j], cln_nodes[j], G_CAFOS, G_CAFOS_pos,lake_name, lake_TP, lake_chla)\n",
    "    ax[5,j].set_title(f\"{lake_name} \\nTP avg = {np.round(lake_TP,1)} \"+ r\"$mg/m^3$\" +f\"\\nchla avg = {np.round(lake_chla,1)} \" +r\"$mg/m^3$\"+f\"\\nAg Land = {np.round(land_frac*100,1)} %\",fontsize= 12,loc='left')\n",
    "    ax[5,j].set_axis_off()\n",
    "    ax[4,j].set_axis_off()\n",
    "    \n",
    "ax[0,0].set_ylabel(f\"Polluted Waterbodies\\n\",fontsize=20)\n",
    "ax[3,0].set_ylabel(f\"Clean Waterbodies\\n\",fontsize=20)\n",
    "line = plt.Line2D([0,1],[.51,.51], color=\"black\", linewidth=1)\n",
    "fig.add_artist(line)\n",
    "plt.savefig(\"Test.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cs2_metrics(node_list, graph):\n",
    "    \n",
    "    def get_ag_frac(all_nodes, lake_gdf, river_gdf, agland, HUC12, HUC10):\n",
    "        rivers = river_gdf[river_gdf.COMID.isin(all_nodes)]\n",
    "        lakes  = lake_gdf[lake_gdf.COMID.isin(all_nodes)]\n",
    "        \n",
    "        huc12_rivs  = [i for i in rivers.huc12.values]\n",
    "        \n",
    "        huc12_lakes = [i for i in lakes.huc12.values]\n",
    "        huc12_vals = huc12_lakes + huc12_rivs\n",
    "        huc10_vals = [i for i in lakes.huc10.values]\n",
    "        aglands    = agland[agland.huc12.isin(huc12_vals)]\n",
    "        huc12s     = HUC12[HUC12.huc12.isin(huc12_vals)]\n",
    "        huc10s     = HUC10[HUC10.huc10.isin(huc10_vals)]\n",
    "        \n",
    "        aglands    = agland[agland.huc12.isin(huc12_vals)].copy(deep=True)\n",
    "        if node == 6866527:\n",
    "            huc12s = huc12s[huc12s.huc12 < 50000000000]\n",
    "        \n",
    "        huc12s     = HUC12[HUC12.huc12.isin(huc12_vals)]\n",
    "        huc10s     = HUC10[HUC10.huc10.isin(huc10_vals)]\n",
    "        aglands    = gpd.overlay(aglands, huc12s,how=\"intersection\")\n",
    "        \n",
    "        return sum(aglands.area)/sum(huc12s.area)\n",
    "    \n",
    "    count_CAFOS        = 0\n",
    "    count_not_in_graph = 0\n",
    "    count_in_graph     = 0\n",
    "    count_ag_frac50    = 0\n",
    "    count_10_nodes     = 0\n",
    "    count_50_nodes     = 0\n",
    "    count_headwater    = 0\n",
    "    tot                = len(node_list)\n",
    "    \n",
    "    gnodes = [i for i in graph.nodes]\n",
    "    \n",
    "    # check if cafo is in huc12 watershed if lake is in graph but not connected to cafo\n",
    "    \n",
    "    ag_fracs = []\n",
    "    \n",
    "    for k, node in enumerate(node_list):\n",
    "        if np.isin(node, gnodes):\n",
    "            count_in_graph += 1\n",
    "            \n",
    "\n",
    "            \n",
    "            g, cols = get_upstream_graph(graph, node, WILakes, WIRivers)\n",
    "            subnodes = [i for i in g.nodes]\n",
    "            if len(subnodes) == 0:\n",
    "                count_headwater += 1\n",
    "                \n",
    "                huc12_val = WILakes.huc12[WILakes.COMID == node].iloc[0]\n",
    "                \n",
    "                if len(CAFOS[CAFOS.huc12 == huc12_val]) > 0:\n",
    "                    count_CAFOS += 1\n",
    "            \n",
    "            ag_frac_val = get_ag_frac(subnodes + [node], WILakes, WIRivers, agland, HUC12, HUC10)\n",
    "            ag_fracs = np.append(ag_fracs, ag_frac_val)\n",
    "            \n",
    "            \n",
    "            if ag_frac_val > .5:\n",
    "                count_ag_frac50 += 1\n",
    "            \n",
    "            if len(subnodes) > 10:\n",
    "                count_10_nodes += 1\n",
    "                \n",
    "            if len(subnodes) > 50:\n",
    "                count_50_nodes += 1\n",
    "                \n",
    "            for i in subnodes:\n",
    "                if np.isin(i, CAFOS.Node.values):\n",
    "                    count_CAFOS += 1\n",
    "                    break\n",
    "            \n",
    "        else:\n",
    "            count_not_in_graph += 1\n",
    "            huc12_val = WILakes.huc12[WILakes.COMID == node].iloc[0]\n",
    "                \n",
    "            if len(CAFOS[CAFOS.huc12 == huc12_val]) > 0:\n",
    "                count_CAFOS += 1\n",
    "                \n",
    "            ag_frac_val = get_ag_frac([node], WILakes, WIRivers, agland, HUC12, HUC10)\n",
    "            ag_fracs = np.append(ag_fracs, ag_frac_val)\n",
    "        #print(\"Done with iteration \", k, \"out of \", len(node_list))\n",
    "                \n",
    "    print()\n",
    "    print(\"The number of lakes connected to CAFOS is             \", count_CAFOS, \"  \", count_CAFOS/tot)\n",
    "    print(\"The number of lakes not in the graph is               \", count_not_in_graph, \"   \", count_not_in_graph/tot)\n",
    "    print(\"The number of lakes in the graph is                   \", count_in_graph, \"   \", count_in_graph/tot)\n",
    "    print(\"The number of lakes that are headwaters is            \", count_headwater, \"   \", count_headwater/tot)\n",
    "    print(\"The number of lakes with a 50% ag fraction is         \", count_ag_frac50, \"   \", count_ag_frac50/tot)\n",
    "    print(\"The number of lakes connected to 10 upstream nodes is \", count_10_nodes, \"   \", count_10_nodes/tot)\n",
    "    print(\"The number of lakes connected to 50 upstream nodes is \", count_50_nodes, \"   \", count_50_nodes/tot)\n",
    "    print()\n",
    "    print(\"The average agricultural land fraction is \", np.average(ag_fracs))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eut_general_COMIDs = np.unique(lake_index.COMID.values[(lake_index.TPavg>60) & (lake_index.chlaavg>15)]).astype(int)\n",
    "cln_general_COMIDs = np.unique(lake_index.COMID.values[(lake_index.TPavg<15) & (lake_index.chlaavg<5) & (lake_index.TPavg != 0) & (lake_index.chlaavg != 0)]).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_cs2_metrics(eut_general_COMIDs, G_CAFOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "get_cs2_metrics(cln_general_COMIDs, G_CAFOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
